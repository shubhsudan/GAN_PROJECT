import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torch.utils.tensorboard import SummaryWriter
import torchvision
from torchvision.datasets import ImageFolder




class Generator(nn.Module):
    def __init__(self, latent_dim, image_shape=(3, 100, 100)):
        super(Generator, self).__init__()
        self.latent_dim = latent_dim
        self.image_shape = image_shape
        self.model = nn.Sequential(
            nn.Linear(self.latent_dim, 128),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(128, 256),
            nn.BatchNorm1d(256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(256, 512),
            nn.BatchNorm1d(512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, torch.prod(torch.tensor(self.image_shape)))
        )

    def forward(self, z):
        img = self.model(z)
        return img.view(img.size(0), *self.image_shape)

class Discriminator(nn.Module):
    def __init__(self, image_shape=(3, 100, 100)):
        super(Discriminator, self).__init__()
        self.image_shape = image_shape
        self.model = nn.Sequential(
            nn.Linear(torch.prod(torch.tensor(self.image_shape)), 512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

    def forward(self, img):
        img_flat = img.view(img.size(0), -1)
        validity = self.model(img_flat)
        return validity

# Initialize networks
latent_dim = 120
generator = Generator(latent_dim)
discriminator = Discriminator()

# Loss function and optimizer
adversarial_loss = nn.BCELoss()
optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

# Tensorboard Writer
writer = SummaryWriter()

# Dataset
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])
df = ImageFolder(root='/Users/shubh/Pictures/GAN_PROJECT_DATA/RESIZED_IMAGES',transform=transform)
dataloader = DataLoader(df, batch_size=64, shuffle=True)

device = torch.device("cuda:0" if torch.cuda.is_available() else 'cpu')

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import matplotlib.pyplot as plt

# Assuming you have defined your model, optimizer, criterion, dataloader, etc.

# Training loop
num_epochs = 200
losses = []

for epoch in range(num_epochs):
    for i, (imgs, _) in enumerate(dataloader):
        # Adversarial ground truths
        valid = torch.ones(imgs.size(0), 1, device=device)
        fake = torch.zeros(imgs.size(0), 1, device=device)

        # Configure input
        real_imgs = imgs.to(device)

        # Train Generator
        optimizer_G.zero_grad()
        z = torch.randn(imgs.size(0), latent_dim, device=device)
        gen_imgs = generator(z)
        g_loss = adversarial_loss(discriminator(gen_imgs), valid)
        g_loss.backward()
        optimizer_G.step()

        # Train Discriminator
        optimizer_D.zero_grad()
        real_loss = adversarial_loss(discriminator(real_imgs), valid)
        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)
        d_loss = (real_loss + fake_loss) / 2
        d_loss.backward()
        optimizer_D.step()

        # Print process
        batches_done = epoch * len(dataloader) + i
        if batches_done % sample_interval == 0:
            print(
                f"[Epoch {epoch+1}/{num_epochs}] [Batch {i}/{len(dataloader)}] [D Loss: {d_loss.item()}] [G Loss: {g_loss.item()}]"
            )
            # Tensorboard logging
            writer.add_scalar('Loss/Discriminator', d_loss.item(), batches_done)
            writer.add_scalar('Loss/Generator', g_loss.item(), batches_done)

            # Save generated images
            if epoch % 10 == 0:
                torchvision.utils.save_image(gen_imgs.data[:25], f"/Users/shubh/Desktop/SEMS/SEM_6/PROJECTS_SEM_6/GAN_PROJECT/EPOCH_1/epoch_{epoch}.png", nrow=5, normalize=True)

        # Update losses
        losses.append((d_loss.item(), g_loss.item()))

# Plot the loss curve
plt.figure(figsize=(10, 5))
plt.plot([i[0] for i in losses], label='Discriminator Loss', alpha=0.5)
plt.plot([i[1] for i in losses], label='Generator Loss', alpha=0.5)
plt.xlabel('iteration')
plt.ylabel('Loss')
plt.title('Training Loss Curve')
plt.legend()
plt.show()
