import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
from torchvision.transforms import Compose, Resize, ToTensor, Normalize
import torchvision.utils as vutils
import os

# Hyperparameters
batch_size = 64
image_size = 64  # Adjust this based on your image resolution
channels = 3  # For RGB images
z_dim = 100  # Dimension of the noise vector
n_epochs = 100
learning_rate = 0.0002

# Data Preprocessing
transform = Compose([
    Resize(image_size),
    ToTensor(),
    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

dataset = ImageFolder('D:/lanes/RESIZED_IMAGES', transform=transform)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Generator
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.main = nn.Sequential(
            nn.ConvTranspose2d(z_dim, 512, 4, 1, 0, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(True),
            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(True),
            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(True),
            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(True),
            nn.ConvTranspose2d(64, channels, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    def forward(self, z):
        return self.main(z)

# Discriminator
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(channels, 64, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(128, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(256, 512, 4, 2, 1, bias=False),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(512, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.main(x)

# Initialization
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
generator = Generator().to(device)
discriminator = Discriminator().to(device)

# Loss and Optimizers
criterion = nn.BCELoss()
gen_optimizer = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))
disc_optimizer = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))

# Create a directory to save the generated images
os.makedirs('generated_images', exist_ok=True)

# Training Loop
for epoch in range(n_epochs):
    for real_images, _ in dataloader:
        real_images = real_images.to(device)
        batch_size = real_images.size(0)

        # Train Discriminator
        disc_optimizer.zero_grad()

        # Real Images
        real_preds = discriminator(real_images)
        real_gt = torch.ones(real_preds.size()).to(device)
        real_loss = criterion(real_preds, real_gt)

        # Fake Images
        z = torch.randn(batch_size, z_dim, 1, 1).to(device)
        fake_images = generator(z)
        fake_preds = discriminator(fake_images.detach())
        fake_gt = torch.zeros(fake_preds.size()).to(device)
        fake_loss = criterion(fake_preds, fake_gt)

        disc_loss = real_loss + fake_loss
        disc_loss.backward()
        disc_optimizer.step()

        # Train Generator
        gen_optimizer.zero_grad()

        z = torch.randn(batch_size, z_dim, 1, 1).to(device)
        fake_images = generator(z)
        fake_preds = discriminator(fake_images)
        gen_gt = torch.ones(fake_preds.size()).to(device)
        gen_loss = criterion(fake_preds, gen_gt)

        gen_loss.backward()
        gen_optimizer.step()
        
        

        # Print losses and save generated images
        if (epoch + 1) % 10 == 0:
            print(f'Epoch [{epoch+1}/{n_epochs}], Discriminator Loss: {disc_loss.item():.4f}, Generator Loss: {gen_loss.item():.4f}')
            for i, img in enumerate(fake_images):
                vutils.save_image(img, f'generated_images/epoch_{epoch+1}_image_{i}.png')
          

# Generate Samples
z = torch.randn(batch_size, z_dim, 1, 1).to(device)
generated_images = generator(z)

# Save the final generated images
for i, img in enumerate(generated_images):
    vutils.save_image(img, f'generated_images/final_image_{i}.png')
    
